{"cells":[{"cell_type":"markdown","id":"b1a6973d-a53e-426c-ab59-b7838a60dee1","metadata":{"id":"b1a6973d-a53e-426c-ab59-b7838a60dee1"},"source":["# Image Recognition and Classification AI"]},{"cell_type":"code","execution_count":null,"id":"a74cfaf6-f5e6-4ae1-a8c0-d572f465e41f","metadata":{"id":"a74cfaf6-f5e6-4ae1-a8c0-d572f465e41f"},"outputs":[],"source":["# Required libraries:\n","# keras, tensorflow, pillow, pandas, matplotlib, tabulate, pip install PyQt5\n","\n","from keras.models import load_model\n","from PIL import Image, ImageOps\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","from datetime import datetime\n","import shutil"]},{"cell_type":"markdown","id":"1c082014-2a90-4322-b39e-8e29a6511d00","metadata":{"id":"1c082014-2a90-4322-b39e-8e29a6511d00"},"source":["## User specified directories"]},{"cell_type":"code","execution_count":null,"id":"9eac6e3c-552d-4805-991e-a53354829208","metadata":{"id":"9eac6e3c-552d-4805-991e-a53354829208"},"outputs":[],"source":["### Specify directories ###\n","\n","# Load the model\n","# model_dir = 'Animal_AI_model/animal_keras_model.h5'\n","model_dir = '3yp/trained_classifier'\n","\n","# Path to image folder\n","image_dir = '3yp/classifier_testing'\n","\n","# Class labels txt file\n","# labels_file_dir = 'Animal_AI_model/labels.txt'\n","labels_file_dir = '3yp/classifier.txt'\n","\n","# CONF Threshold\n","conf_threshold = 0.9\n","\n","# Auto Sort images\n","auto_sort_images = True\n","\n","##################"]},{"cell_type":"code","execution_count":null,"id":"43ee63db-d39a-4311-99b2-7e8bfff39129","metadata":{"id":"43ee63db-d39a-4311-99b2-7e8bfff39129","outputId":"2881e4e6-ef82-48d5-b0e9-92d06571e90f"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]}],"source":["model = load_model(model_dir)"]},{"cell_type":"markdown","id":"9b0d366f-cd94-4956-a850-c204f81bed8e","metadata":{"id":"9b0d366f-cd94-4956-a850-c204f81bed8e"},"source":["## Data preparation:\n","- Creates results dataframe\n","- Reads labels file"]},{"cell_type":"code","execution_count":null,"id":"3c9ad5b7-7122-4bdc-ac6d-e16fae9f51c5","metadata":{"id":"3c9ad5b7-7122-4bdc-ac6d-e16fae9f51c5"},"outputs":[],"source":["def create_df_load_classes():\n","    \n","    # Create pandas dataframe to store data\n","    results_df = pd.DataFrame(columns=['Image_Name','Class_1','CONF_class_1','Class_2','CONF_class_2','Class3','CONF_class_3'])\n","    \n","    # Read text file into array\n","    with open(labels_file_dir) as f:\n","        lines = f.readlines()    \n","        \n","    # Clean each array entry by removing \\n and number\n","    final_clss_list = []\n","\n","    for entry in lines:\n","        # Remove \\n\n","        entry = entry.rstrip()\n","\n","        # Remove index number\n","        entry = entry.split(\" \", 1)\n","\n","        # Append to new list\n","        final_clss_list.append(entry[1])\n","        \n","    return results_df, final_clss_list"]},{"cell_type":"markdown","id":"3756b188-dda5-479a-bda6-5cc45b54b08e","metadata":{"id":"3756b188-dda5-479a-bda6-5cc45b54b08e"},"source":["## Runs one inference & get results\n","\n","- Prepares image for inference\n","- Runs the inference\n","- Then retrieves top 3 classes, if above certain threshold\n","- print class name and CONF level"]},{"cell_type":"code","execution_count":null,"id":"5d0a9016-4366-4644-be79-73c4e366dd7f","metadata":{"id":"5d0a9016-4366-4644-be79-73c4e366dd7f"},"outputs":[],"source":["def run_one_inference(results_df, final_clss_list, img, curr_time):\n","    \n","    #### Prepares for inference ####\n","    # Load image\n","    image = Image.open(os.path.join(image_dir, img))\n","\n","    # Creates array of the right shape to feed into the keras model\n","    # The 'length' or number of images you can put into the array is\n","    # determined by the first position in the shape tuple, in this case 1.\n","    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n","\n","    #resize the image to a 224x224 with the same strategy as in TM2:\n","    #resizing the image to be at least 224x224 and then cropping from the center\n","    size = (224, 224)\n","    image = ImageOps.fit(image, size, Image.ANTIALIAS)\n","\n","    #turn the image into a numpy array\n","    image_array = np.asarray(image)\n","    # Normalize the image\n","    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n","    # Load the image into the array\n","    data[0] = normalized_image_array\n","    \n","    \n","    \n","    #### run the inference & get scores ####\n","    prediction = model.predict(data)\n","\n","    # Convert to list\n","    prediction = prediction[0].tolist()\n","#     print(prediction)\n","\n","\n","\n","    #### Prints top 3 classes and CONF level (if classes =>3) ####\n","    if len(prediction) >= 3:\n","        num_classes = 3\n","    else:\n","        num_classes = len(prediction)\n","\n","    # Sort by CONF level\n","    prediction_sorted = sorted(prediction, reverse=True)\n","#     print(prediction_sorted)\n","    \n","    \n","    \n","    #### Match CONF level to class name & add entry to DF ####\n","    new_df_entry = []\n","\n","    # Get filename\n","    new_df_entry.append(img)\n","\n","    for i in range(num_classes):\n","        curr_val = prediction_sorted[i]\n","\n","        # Only proceed to append if prediction score exceeds threshold\n","        if curr_val >= conf_threshold:\n","            idx = prediction.index(curr_val)\n","            new_df_entry.append(final_clss_list[idx])\n","            new_df_entry.append(round(curr_val, 4))\n","            \n","            \n","    # Auto move images into respective folders if asked to\n","    if auto_sort_images:\n","        \n","        # Create categorised folder to copy images into\n","        categorised_dir = os.path.join(image_dir, f'Categorised_Images_{curr_time}')\n","        if not os.path.exists(categorised_dir):\n","            os.makedirs(categorised_dir)\n","                \n","        # Retrieve class name\n","        curr_val2 = prediction_sorted[0]\n","        if curr_val2 >= conf_threshold:\n","            main_class_name = final_clss_list[prediction.index(curr_val2)]\n","        else:\n","            main_class_name = 'Not Sure'\n","            \n","        # Copy images over  \n","        copy_one_image(img, main_class_name, categorised_dir)\n","\n","        \n","    # Pad list\n","    df_row_length = 7\n","    if len(new_df_entry)<df_row_length:\n","        new_df_entry += [''] * (df_row_length - len(new_df_entry))\n","\n","    # Add to DF\n","    updated_df = pd.Series(new_df_entry, index = results_df.columns)\n","    results_df = results_df.append(updated_df, ignore_index=True)\n","    \n","    return results_df"]},{"cell_type":"markdown","id":"1b911acf-2411-4111-a34c-63a302fe9ec1","metadata":{"id":"1b911acf-2411-4111-a34c-63a302fe9ec1"},"source":["## Moves images to correct folders function"]},{"cell_type":"code","execution_count":null,"id":"56504917-61b1-4925-88bd-b4f1ccdedbdd","metadata":{"id":"56504917-61b1-4925-88bd-b4f1ccdedbdd"},"outputs":[],"source":["def copy_one_image(img, main_class_name, categorised_dir):\n","    \n","    # Create new folder if does not exist\n","    target_path = os.path.join(categorised_dir, main_class_name)\n","    if not os.path.exists(target_path):\n","        os.makedirs(target_path)\n","        \n","    # Copy image over to right folder\n","    orginal_dir = os.path.join(image_dir, img)\n","    shutil.copy2(orginal_dir, target_path)"]},{"cell_type":"markdown","id":"9ef815f2-34af-4269-923f-c1a68731a1e3","metadata":{"id":"9ef815f2-34af-4269-923f-c1a68731a1e3"},"source":["## Runs inference for all"]},{"cell_type":"code","execution_count":null,"id":"41fa788e-b666-45a9-b3f8-1a26d102ef11","metadata":{"id":"41fa788e-b666-45a9-b3f8-1a26d102ef11"},"outputs":[],"source":["def run_inference(results_df, final_clss_list):\n","    \n","    # Get list of all images\n","    img_list = [name for name in os.listdir(image_dir) \n","            if os.path.isfile(os.path.join(image_dir, name)) and name.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff'))]\n","    \n","    print(f\"Analysing {len(img_list)} suitable images... Pls wait\\n\")\n","    \n","    \n","    # Create output folder\n","    curr_time = datetime.now().strftime(\"%m_%d-%H.%M.%S\")\n","    results_dir = os.path.join(image_dir, f\"Analysis_Results_{curr_time}\")\n","    if not os.path.exists(results_dir):\n","        os.makedirs(results_dir)\n","    \n","    # Repeats inference for all images in the folder\n","    for j, img in enumerate(img_list):\n","        results_df = run_one_inference(results_df, final_clss_list, img, curr_time)\n","        if j%5==0:\n","            print(f\"{j}/{len(img_list)} images analysed...\")\n","        elif j==len(img_list)-1:\n","            print(f\"{j+1}/{len(img_list)} images analysed...\")\n","    \n","    # Save to CSV\n","    results_df.to_csv(f'{results_dir}/results.csv', encoding='utf-8')\n","    print(\"\\n>> Analysis complete! Generating plots...\")\n","    \n","    # Moving images progress\n","    if auto_sort_images:\n","        print(\"\\n>> Sorting images into the correct folders... See the 'Categorised_Images' folder in your images folder for results.\")\n","    \n","    return results_df, results_dir"]},{"cell_type":"markdown","id":"99200038-84f0-4da8-ac03-e78457885186","metadata":{"id":"99200038-84f0-4da8-ac03-e78457885186"},"source":["## Generates plots"]},{"cell_type":"code","execution_count":null,"id":"91687fa9-f9e4-4cc2-b185-0af3317c9f7e","metadata":{"id":"91687fa9-f9e4-4cc2-b185-0af3317c9f7e"},"outputs":[],"source":["def generate_plots(results_df, results_dir):\n","    \n","    # Counts frequency of each occurence\n","    results_df['Class_1'] = results_df['Class_1'].replace('', 'Not identified')\n","    freq_table = results_df['Class_1'].value_counts()\n","\n","    # Plots bar graph and saves it\n","    fig1 = plt.figure(figsize=(10, 6), dpi=80)\n","    freq_table.plot.bar()\n","    plt.xticks(rotation=30, ha='right', wrap=True)\n","    plt.title('Bar Chart - Number of images per type', fontsize=18)\n","    plt.xlabel('Image Type', fontsize=16)\n","    plt.ylabel('Frequency', fontsize=16)\n","    plt.subplots_adjust(bottom=0.3)\n","    plt.savefig(f\"{results_dir}/bar_chart.jpg\")\n","    plt.close()\n","\n","    # Plots pie chart and saves it\n","    fig2 = plt.figure(figsize=(10, 6), dpi=80)\n","    freq_table.plot.pie(autopct='%1.2f%%')\n","    plt.title('Pie Chart - Type Compositon', fontsize=18)\n","    plt.subplots_adjust(bottom=0.1, left=0.2, right=0.8)\n","    plt.savefig(f\"{results_dir}/pie_chart.jpg\")\n","    plt.close()"]},{"cell_type":"markdown","id":"08512578-e277-4749-997b-818526216d97","metadata":{"id":"08512578-e277-4749-997b-818526216d97"},"source":["## Main Function"]},{"cell_type":"code","execution_count":null,"id":"44e166d2-bbd2-4dcf-bc5a-d4c2bbeb7904","metadata":{"id":"44e166d2-bbd2-4dcf-bc5a-d4c2bbeb7904"},"outputs":[],"source":["def main():\n","    results_df, final_clss_list = create_df_load_classes()\n","    results_df, results_dir = run_inference(results_df, final_clss_list)\n","    generate_plots(results_df, results_dir)\n","    \n","    print(\"\\n>> All done. Results CSV and Plots saved in the 'Analysis_Results' folder with your test images.\")\n","    \n","    # Some instructions\n","    print(\"\\n-----------------------------------------\\n\")\n","    print(\"**HOW TO UNDERSTAND THE RESULTS CSV:**\")\n","    print(\"Class_1 refers to most confident type of class identified, with the associated confidence score in CONF_class_1 column. The next confident class is Class_2 and so on.\") \n","    print(\"If certain columns are blank, it means the confidence level is below the threshold you set. Decrease the threshold to get more data, if needed.\")"]},{"cell_type":"code","execution_count":null,"id":"6b20c090-7680-4046-bcc3-de31534d0228","metadata":{"id":"6b20c090-7680-4046-bcc3-de31534d0228","outputId":"3a850259-f11c-4e03-95de-015948c6f4ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Analysing 27 suitable images... Pls wait\n","\n","0/27 images analysed...\n","5/27 images analysed...\n","10/27 images analysed...\n","15/27 images analysed...\n","20/27 images analysed...\n","25/27 images analysed...\n","27/27 images analysed...\n","\n","Analysis complete! Generating plots...\n","\n","Sorting images into the correct folders... See the 'Categorised_Images' folder in your images folder for results.\n","\n","All done. Results CSV and Plots saved in the 'Analysis_Results' folder with your test images.\n","\n","-----------------------------------------\n","\n","**HOW TO UNDERSTAND THE RESULTS CSV:**\n","Class_1 refers to most confident type of class identified, with the associated confidence score in CONF_class_1 column. The next confident class is Class_2 and so on.\n","If certain columns are blank, it means the confidence level is below the threshold you set. Decrease the threshold to get more data, if needed.\n"]}],"source":["# main()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"colab":{"name":"Image_AI.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}